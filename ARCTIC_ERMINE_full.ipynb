{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from astropy.coordinates import FK5, SkyCoord\n",
    "import astropy.io.fits as pyfits\n",
    "from astropy.io import ascii\n",
    "from astropy.stats import sigma_clipped_stats, mad_std\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from astropy.visualization import SqrtStretch, SinhStretch, MinMaxInterval, PercentileInterval, ZScaleInterval\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import csv\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import photutils as pt\n",
    "from photutils import DAOStarFinder, find_peaks, aperture_photometry, CircularAperture\n",
    "\n",
    "from progress.bar import ChargingBar\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.signal\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore overwriting reduced files warnings in case you need to rerun\n",
    "warnings.filterwarnings('ignore', message='Overwriting existing file')\n",
    "\n",
    "# ignore overflow errors\n",
    "warnings.filterwarnings('ignore', message='overflow encountered in sinh')\n",
    "\n",
    "# ignore everything, maybe don't do this?\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tell me where your raw data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the directory where your data is stored: /Users/Hannah/iraf/images/2019Q3UV01/Q3UV01/UT190727/\n",
      "The directory you entered is: /Users/Hannah/iraf/images/2019Q3UV01/Q3UV01/UT190727/\n"
     ]
    }
   ],
   "source": [
    "raw_data_direc = input (\"Enter the directory where your data is stored: \")\n",
    "test_direc = str(raw_data_direc)\n",
    "print(\"The directory you entered is:\", test_direc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Reduction -- Creates /reduced/cals/ and /reduced/data/ directories, and fills those directories with reduced calibration and science images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cals_direc = os.path.join(raw_data_direc, 'reduced', 'cals')\n",
    "reduced_direc = os.path.join(raw_data_direc, 'reduced', 'data')\n",
    "\n",
    "# directories for reduced images\n",
    "if not os.path.exists(cals_direc):\n",
    "    os.makedirs(cals_direc)\n",
    "if not os.path.exists(reduced_direc):\n",
    "    os.makedirs(reduced_direc) \n",
    "\n",
    "# grab all files from the data directory; organize dataframe\n",
    "files = glob.glob(os.path.join(raw_data_direc, \"*.fits\"))\n",
    "\n",
    "df = pd.DataFrame(files,columns=['fname'])\n",
    "df['objtype'] = pd.Series(\"\", index=df.index)\n",
    "df['filt'] = pd.Series(\"\", index=df.index)\n",
    "df['exp'] = pd.Series(\"\", index=df.index)\n",
    "df['objname'] = pd.Series(\"\", index=df.index)\n",
    "\n",
    "for ff,fname in enumerate(files):\n",
    "    try:\n",
    "        df['objtype'][ff] = pyfits.open(fname)[0].header['IMAGETYP']\n",
    "        df['filt'][ff] = pyfits.open(fname)[0].header['FILTER']\n",
    "        df['exp'][ff] = pyfits.open(fname)[0].header['EXPTIME']\n",
    "        df['objname'][ff] = pyfits.open(fname)[0].header['OBJNAME']\n",
    "    except IOError:\n",
    "        print('\\n File corrupt or missing: ' + fname)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_image(f, overscan_poly_order = 5):\n",
    "    \"\"\"\n",
    "    trim_image returns a trimmed version of the raw image. The ARCTIC detector is structured in four quadrants which can be read out individually (Quad Mode) or as a whole (Lower Left Mode) and trim_image identifies which readout mode was used and crops the image accordingly.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : raw fits image from ARCTIC\n",
    "    overscan_poly_order : order of polynomial used to fit overscan\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    alldat : a list with [the image in a numpy array, the astropy header]\n",
    "    \"\"\"\n",
    "    \n",
    "    datfile = pyfits.getdata(f, header=True)\n",
    "    dat_raw = datfile[0]\n",
    "    dat_head = datfile[1]\n",
    "    \n",
    "    amp = pyfits.open(f)[0].header['READAMPS']\n",
    "    \n",
    "    if amp == \"Quad\":\n",
    "        # ll, ul, lr, ur\n",
    "        quads = ['DSEC11', 'DSEC21', 'DSEC12', 'DSEC22']\n",
    "        biases = ['BSEC11', 'BSEC21', 'BSEC12', 'BSEC22']\n",
    "        \n",
    "        dat = [[],[],[],[]]\n",
    "        for i,quad in enumerate(quads):\n",
    "            idx_string = pyfits.open(f)[0].header[quad]\n",
    "            idx = re.split('[: ,]',idx_string.rstrip(']').lstrip('['))\n",
    "            dat[i] = dat_raw[int(idx[2])-1:int(idx[3]),int(idx[0])-1:int(idx[1])].astype(np.float64)\n",
    "    \n",
    "        over = [[],[],[],[]]\n",
    "        avg_overscan = [[],[],[],[]]\n",
    "        row_idx = [[],[],[],[]]\n",
    "        p = [[],[],[],[]]\n",
    "        fit_overscan = [[],[],[],[]]\n",
    "        fit_overscan_col = [[],[],[],[]]\n",
    "        \n",
    "        for j,bias in enumerate(biases):\n",
    "            idx_over_string = pyfits.open(f)[0].header[bias]\n",
    "            idx_over = re.split('[: ,]',idx_over_string.rstrip(']').lstrip('['))\n",
    "            over[j] = dat_raw[int(idx_over[2])-1:int(idx_over[3]),int(idx_over[0])-1:int(idx_over[1])]\n",
    "            \n",
    "            #Average along columns\n",
    "            avg_overscan[j] = np.mean(over[j],axis=1)\n",
    "            #Index array, then fit!\n",
    "            row_idx[j] = np.arange(len(avg_overscan[j]))\n",
    "            p[j] = np.polyfit(row_idx[j],avg_overscan[j],deg=overscan_poly_order)\n",
    "            #Calculate array from fit, then transpose into a column\n",
    "            fit_overscan[j] = np.poly1d(p[j])(row_idx[j])\n",
    "            fit_overscan_col[j] = fit_overscan[j][:,np.newaxis]\n",
    "        \n",
    "        #Subtract column!\n",
    "        dat[0] -= fit_overscan_col[0]\n",
    "        dat[1] -= fit_overscan_col[1]\n",
    "        dat[2] -= fit_overscan_col[2]\n",
    "        dat[3] -= fit_overscan_col[3]\n",
    "        \n",
    "        sci_lo = np.concatenate((dat[2], dat[3]), axis = 1)\n",
    "        sci_up = np.concatenate((dat[0], dat[1]), axis = 1)\n",
    "        sci = np.concatenate((sci_up, sci_lo), axis = 0)\n",
    "\n",
    "    if amp == 'LL':\n",
    "        idx_string = pyfits.open(f)[0].header['DSEC11']\n",
    "        idx = re.split('[: ,]',idx_string.rstrip(']').lstrip('['))\n",
    "        sci = dat_raw[int(idx[2])-1:int(idx[3]),int(idx[0])-1:int(idx[1])].astype(np.float64)\n",
    "    \n",
    "        idx_over_string = pyfits.open(f)[0].header['BSEC11']\n",
    "        idx_over = re.split('[: ,]',idx_over_string.rstrip(']').lstrip('['))\n",
    "        over = dat_raw[int(idx_over[2])-1:int(idx_over[3]),int(idx_over[0])-1:int(idx_over[1])]\n",
    "        \n",
    "        #Average along columns\n",
    "        avg_overscan = np.mean(over,axis=1)\n",
    "        #Index array, then fit!\n",
    "        row_idx = np.arange(len(avg_overscan))\n",
    "        p = np.polyfit(row_idx,avg_overscan,deg=overscan_poly_order)\n",
    "        #Calculate array from fit, then transpose into a column\n",
    "        fit_overscan = np.poly1d(p)(row_idx)\n",
    "        fit_overscan_col = fit_overscan[:,np.newaxis]\n",
    "        #Subtract column!\n",
    "        sci -= fit_overscan_col\n",
    "    \n",
    "    alldat = [sci,dat_head]\n",
    "    return alldat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdark(expt):\n",
    "    \"\"\"\n",
    "    Generate a dark given an exposure time or scale down from longest dark available\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    expt : exposure time (in the data frame: df['exp'])\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dark : dark image for that exposure time (numpy array)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        dark = pyfits.getdata(os.path.join(cals_direc,'master_dark_{0}.fits'.format(expt)))\n",
    "    except IOError:\n",
    "        scaleto = np.max(df['exp'][df['exp'] != ''])\n",
    "        dark = pyfits.getdata(os.path.join(cals_direc,'master_dark_{0}.fits'.format(scaleto)))\n",
    "        dark *= (expt/scaleto)\n",
    "    return dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> Starting bias combine...\n",
      "   > Created master bias\n"
     ]
    }
   ],
   "source": [
    "### CREATE MASTER BIAS #######################################\n",
    "\n",
    "print('\\n >>> Starting bias combine...')\n",
    "\n",
    "bias_idx = df[df['objtype'] == 'Bias'].index.tolist()\n",
    "if len(bias_idx) == 0:\n",
    "    print('   > No biases found. Continuing reductions...')\n",
    "    bias=0.\n",
    "else:\n",
    "    biases = np.array([trim_image(df['fname'][n])[0] for n in bias_idx])\n",
    "    bias = np.median(biases,axis=0)\n",
    "    pyfits.writeto(os.path.join(cals_direc, 'master_bias.fits'),bias,overwrite=True)\n",
    "    print('   > Created master bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> Starting darks...\n",
      "   > No darks found for exposure time 5.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 7.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 15.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 20.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 10.0 sec. Continuing reductions...\n",
      "   > Created master 60.0 second dark\n",
      "   > No darks found for exposure time 12.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 8.0 sec. Continuing reductions...\n",
      "   > No darks found for exposure time 30.0 sec. Continuing reductions...\n"
     ]
    }
   ],
   "source": [
    "### CREATE MASTER DARKS ######################################\n",
    "### these are bias subtracted\n",
    "\n",
    "# array of all exposure times found\n",
    "times = list(filter(None,pd.unique(df.exp.ravel())))\n",
    "\n",
    "print('\\n >>> Starting darks...')\n",
    "\n",
    "for ii in range(0,len(times)):\n",
    "    dark_idx = df[(df['exp'] == times[ii]) & (df['objtype'] == 'Dark')].index.tolist()\n",
    "    if len(dark_idx) == 0:\n",
    "        print('   > No darks found for exposure time ' + str(times[ii]) + ' sec. Continuing reductions...')\n",
    "    else:\n",
    "        darks = np.array([trim_image(df['fname'][n])[0] for n in dark_idx]) - bias\n",
    "        dark_final = np.median(darks,axis=0)\n",
    "        \n",
    "        name = os.path.join(cals_direc,'master_dark_{0}.fits'.format(times[ii]))\n",
    "        pyfits.writeto(name,dark_final,overwrite=True)\n",
    "        print('   > Created master '+ str(times[ii])+' second dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> Starting flats...\n",
      "   > Exposure time 5.0 sec. No dark correction neccessary.\n",
      "   > Created master r flat\n",
      "   > Exposure time 15.0 sec. No dark correction neccessary.\n",
      "   > Created master g flat\n"
     ]
    }
   ],
   "source": [
    "### CREATE MASTER FLATS ######################################\n",
    "### these are bias and dark subtracted, then normalized\n",
    "\n",
    "# array of all filters found\n",
    "filters = list(filter(None,pd.unique(df.filt.ravel())))\n",
    "\n",
    "print('\\n >>> Starting flats...')\n",
    "\n",
    "for ii in range(0,len(filters)):\n",
    "    flat_idx = df[(df['filt'] == filters[ii]) & (df['objtype'] == 'Flat')].index.tolist()\n",
    "    if len(flat_idx) == 0:\n",
    "        print('   > No flats found for the ' + str(filters[ii]) + ' filter. Continuing reductions...')\n",
    "    else:\n",
    "        # get the correct master dark. if not exact exp time, scale it\n",
    "        # from the longest dark frame. if no darks at all, continue.\n",
    "        expt = df['exp'][flat_idx[0]]\n",
    "        if expt > 60.0:\n",
    "            try:\n",
    "                dark = getdark(expt)\n",
    "            except IOError:\n",
    "                print('   > No darks found for exposure time ' + str(expt) + ' sec. Continuing reductions...')\n",
    "                dark = 0.\n",
    "        else:\n",
    "            print('   > Exposure time ' + str(expt) + ' sec. No dark correction neccessary.')\n",
    "            dark = 0.\n",
    "\n",
    "        flats = np.array([trim_image(df['fname'][n])[0] for n in flat_idx]) - bias - dark\n",
    "        flat_final = np.median(flats,axis=0)\n",
    "        flat_final /= np.max(flat_final)\n",
    "\n",
    "        new_filter_name = filters[ii].strip(\"#2\")\n",
    "        filts = new_filter_name[-1]\n",
    "        name = os.path.join(cals_direc, 'master_flat_{0}.fits'.format(filts))\n",
    "        pyfits.writeto(name,flat_final,overwrite=True)\n",
    "        print('   > Created master '+ str(new_filter_name[-1])+' flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> 75 science images found. Starting reductions...\n",
      "   > Exposure time 5.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 20.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 8.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 5.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 15.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 15.0 sec. No dark correction necessary.\n",
      "   > Exposure time 30.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 5.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 20.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 15.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "   > Exposure time 5.0 sec. No dark correction necessary.\n",
      "   > Exposure time 5.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 15.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 7.0 sec. No dark correction necessary.\n",
      "   > Exposure time 12.0 sec. No dark correction necessary.\n",
      "   > Exposure time 15.0 sec. No dark correction necessary.\n",
      "   > Exposure time 10.0 sec. No dark correction necessary.\n",
      "\n",
      " >>> Finished reductions!\n"
     ]
    }
   ],
   "source": [
    "### REDUCE SCIENCE IMAGES ####################################\n",
    "### (raw - dark) / masterflat\n",
    "\n",
    "dat_idx = df[df['objtype'] == 'Object'].index.tolist()\n",
    "\n",
    "print('\\n >>> '+str(len(dat_idx))+' science images found. Starting reductions...')\n",
    "for n in dat_idx:\n",
    "    datfile = trim_image(df['fname'][n])\n",
    "    dat_raw = datfile[0]\n",
    "    dat_head = datfile[1]\n",
    "    \n",
    "    time = df['exp'][n]\n",
    "    if time > 60.0:\n",
    "        try:\n",
    "            dark = getdark(time)\n",
    "        except IOError:\n",
    "            print('   > No darks found for exposure time ' + str(time) + ' sec. Continuing reductions...')\n",
    "            dark = 0.\n",
    "    else:\n",
    "        print('   > Exposure time ' + str(time) + ' sec. No dark correction necessary.')\n",
    "        dark = 0.\n",
    "\n",
    "    new_filter_name = df['filt'][n].strip(\"#2\")\n",
    "    filt = new_filter_name[-1]\n",
    "    try:\n",
    "        flat = flat = pyfits.getdata(os.path.join(cals_direc,'master_flat_{0}.fits'.format(filt)))\n",
    "    except IOError:\n",
    "        print('   > Warning! No ' + str(new_filter_name) + ' filter flat found for ' + df['fname'][n])\n",
    "        flat = 1.\n",
    "    \n",
    "    dat = (dat_raw - dark) / flat\n",
    "    name = os.path.join(reduced_direc,'red_{0}'.format(os.path.basename(df['fname'][n])))\n",
    "    pyfits.writeto(name,dat,overwrite=True,header=dat_head)\n",
    "\n",
    "print('\\n >>> Finished reductions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photometry -- Performs aperture photometry on science images in the /reduced/data/ directory for multiple filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cals_direc = os.path.join(raw_data_direc, 'reduced', 'cals')\n",
    "reduced_direc = os.path.join(raw_data_direc, 'reduced', 'data')\n",
    "results_direc = os.path.join(reduced_direc, 'results')\n",
    "\n",
    "# directories for reduced images\n",
    "if not os.path.exists(cals_direc):\n",
    "    print('   > Reduced cals directory does not exist! Run cells above (Image Reduction section) first.')\n",
    "if not os.path.exists(reduced_direc):\n",
    "    print('   > Reduced data directory does not exist! Run cells above (Image Reduction section) first.')\n",
    "if not os.path.exists(results_direc):\n",
    "    os.makedirs(results_direc)\n",
    "    \n",
    "red_files = glob.glob(os.path.join(reduced_direc, \"*.fits\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitudes -- Converts raw photometry to instrumental magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_direc = os.path.join(reduced_direc, 'results')\n",
    "\n",
    "# directories for reduced images\n",
    "if not os.path.exists(results_direc):\n",
    "    print('   > Results directory does not exist! Run cells above (Photometry section) first.')\n",
    "    \n",
    "mag_files = glob.glob(os.path.join(results_direc, \"*.mag\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting -- Make various plots of the relative magnitudes, flux versus time, airmass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'xtick.labelsize': 14})\n",
    "matplotlib.rcParams.update({'ytick.labelsize': 14})\n",
    "\n",
    "sdss_array = ['u', 'g', 'r', 'i', 'z']\n",
    "color_array = ['royalblue', 'mediumseagreen', 'gold', 'darkorange', 'tomato']\n",
    "\n",
    "res_files = glob.glob(os.path.join(results_direc, \"*.result\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
